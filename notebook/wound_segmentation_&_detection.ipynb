{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Wound Segmentation and Detection using U-Net\n",
        "\n",
        "This notebook presents an end-to-end deep learning pipeline for wound segmentation from medical images using a U-Net architecture.\n",
        "\n",
        "The workflow includes:\n",
        "- Data preprocessing\n",
        "- Model training\n",
        "- Inference on test images\n",
        "- Visual comparison with ground truth masks\n",
        "\n"
      ],
      "metadata": {
        "id": "3kjYwn6ucxhl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omnAUpu0agux",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "#Google Drive is mounted to access training, testing, and model files stored remotely.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('path to drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. Image Preprocessing (Single Image Demonstration)\n",
        "\n",
        "#A single image is preprocessed to demonstrate the standardization pipeline before applying it to the full dataset.\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------------\n",
        "# CONFIG (COLAB + DRIVE)\n",
        "# -------------------------------\n",
        "IMAGE_PATH = \"image path\"\n",
        "IMG_SIZE = 512   # SAME as original → no detail loss\n",
        "\n",
        "# -------------------------------\n",
        "# LOAD IMAGE (PRESERVE QUALITY)\n",
        "# -------------------------------\n",
        "img = cv2.imread(IMAGE_PATH, cv2.IMREAD_COLOR)\n",
        "assert img is not None, \"Image not found. Check path or filename.\"\n",
        "\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# -------------------------------\n",
        "# VERY GENTLE STANDARDIZATION\n",
        "# -------------------------------\n",
        "def ultra_gentle_crop(image, crop_ratio=0.98):\n",
        "    \"\"\"\n",
        "    Removes only tiny borders if present.\n",
        "    Keeps >98% of original pixels.\n",
        "    \"\"\"\n",
        "    h, w, _ = image.shape\n",
        "    ch, cw = int(h * crop_ratio), int(w * crop_ratio)\n",
        "    y1 = (h - ch) // 2\n",
        "    x1 = (w - cw) // 2\n",
        "    return image[y1:y1+ch, x1:x1+cw]\n",
        "\n",
        "img_std = ultra_gentle_crop(img)\n",
        "\n",
        "# -------------------------------\n",
        "# RESIZE (HIGH QUALITY)\n",
        "# -------------------------------\n",
        "img_std = cv2.resize(\n",
        "    img_std,\n",
        "    (IMG_SIZE, IMG_SIZE),\n",
        "    interpolation=cv2.INTER_CUBIC\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# NORMALIZATION (MODEL READY)\n",
        "# -------------------------------\n",
        "img_preprocessed = img_std.astype(np.float32) / 255.0\n",
        "\n",
        "# -------------------------------\n",
        "# DISPLAY COMPARISON\n",
        "# -------------------------------\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Original (512×512)\")\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title(\"Preprocessed (Detail Preserved)\")\n",
        "plt.imshow(img_preprocessed)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5j4KzXyonCHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 3. Batch Preprocessing of Training Images\n",
        "\n",
        "#All training images are standardized to a fixed resolution to ensure consistent input for the U-Net model.\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# CONFIG\n",
        "# -------------------------------r\"\n",
        "INPUT_DIR = \"image path\"\n",
        "OUTPUT_DIR = \"image path\"\n",
        "IMG_SIZE = 512\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------------------\n",
        "# VERY GENTLE STANDARDIZATION\n",
        "# -------------------------------\n",
        "def ultra_gentle_crop(image, crop_ratio=0.98):\n",
        "    h, w, _ = image.shape\n",
        "    ch, cw = int(h * crop_ratio), int(w * crop_ratio)\n",
        "    y1 = (h - ch) // 2\n",
        "    x1 = (w - cw) // 2\n",
        "    return image[y1:y1+ch, x1:x1+cw]\n",
        "\n",
        "# -------------------------------\n",
        "# PROCESS ALL IMAGES\n",
        "# -------------------------------\n",
        "for filename in os.listdir(INPUT_DIR):\n",
        "\n",
        "    if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "        continue\n",
        "\n",
        "    input_path = os.path.join(INPUT_DIR, filename)\n",
        "\n",
        "    # Load image\n",
        "    img = cv2.imread(input_path, cv2.IMREAD_COLOR)\n",
        "    if img is None:\n",
        "        print(f\"Skipping {filename} (cannot read)\")\n",
        "        continue\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Standardization\n",
        "    img_std = ultra_gentle_crop(img)\n",
        "\n",
        "    # Resize (preserve quality)\n",
        "    img_std = cv2.resize(\n",
        "        img_std,\n",
        "        (IMG_SIZE, IMG_SIZE),\n",
        "        interpolation=cv2.INTER_CUBIC\n",
        "    )\n",
        "\n",
        "    # Normalize\n",
        "    img_preprocessed = img_std.astype(np.float32) / 255.0\n",
        "\n",
        "    # Save as lossless PNG\n",
        "    save_path = os.path.join(OUTPUT_DIR, filename)\n",
        "    save_img = (img_preprocessed * 255).astype(np.uint8)\n",
        "    save_img = cv2.cvtColor(save_img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    cv2.imwrite(save_path, save_img)\n",
        "\n",
        "print(\"✅ Preprocessing completed for all images.\")\n"
      ],
      "metadata": {
        "id": "EkkFu6czqfps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. Preprocessing of Segmentation Masks\n",
        "\n",
        "#Ground truth masks are preprocessed using the same spatial operations as images to maintain alignment.\n",
        "#Nearest-neighbor interpolation is used to preserve label integrity.\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# CONFIG (MASKS)\n",
        "# -------------------------------\n",
        "INPUT_DIR = \"image path\"\n",
        "OUTPUT_DIR = \"image path\"\n",
        "IMG_SIZE = 512\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------------------\n",
        "# SAME GENTLE CROP AS IMAGES\n",
        "# -------------------------------\n",
        "def ultra_gentle_crop_mask(mask, crop_ratio=0.98):\n",
        "    h, w = mask.shape\n",
        "    ch, cw = int(h * crop_ratio), int(w * crop_ratio)\n",
        "    y1 = (h - ch) // 2\n",
        "    x1 = (w - cw) // 2\n",
        "    return mask[y1:y1+ch, x1:x1+cw]\n",
        "\n",
        "# -------------------------------\n",
        "# PROCESS ALL MASKS\n",
        "# -------------------------------\n",
        "for filename in os.listdir(INPUT_DIR):\n",
        "\n",
        "    if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "        continue\n",
        "\n",
        "    input_path = os.path.join(INPUT_DIR, filename)\n",
        "\n",
        "    # Load mask as GRAYSCALE\n",
        "    mask = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if mask is None:\n",
        "        print(f\"Skipping {filename} (cannot read)\")\n",
        "        continue\n",
        "\n",
        "    # Crop (same logic as image)\n",
        "    mask = ultra_gentle_crop_mask(mask)\n",
        "\n",
        "    # Resize (NEAREST to preserve labels)\n",
        "    mask = cv2.resize(\n",
        "        mask,\n",
        "        (IMG_SIZE, IMG_SIZE),\n",
        "        interpolation=cv2.INTER_NEAREST\n",
        "    )\n",
        "\n",
        "    # Ensure binary (safety)\n",
        "    _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Save mask\n",
        "    save_path = os.path.join(OUTPUT_DIR, filename)\n",
        "    success = cv2.imwrite(save_path, mask)\n",
        "\n",
        "    if not success:\n",
        "        print(f\"Failed to save {filename}\")\n",
        "\n",
        "print(\"✅ Mask preprocessing completed for all masks.\")\n"
      ],
      "metadata": {
        "id": "h9ELG3ETsR1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"GPU available:\", torch.cuda.is_available())\n",
        "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
      ],
      "metadata": {
        "id": "6Ib3IZjmtbpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 6. Dependency Installation\n",
        "\n",
        "#Required deep learning and utility libraries are installed.\n",
        "!pip install torch torchvision tqdm\n"
      ],
      "metadata": {
        "id": "CKkFgP4BtgRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 7. Custom Dataset Definition\n",
        "\n",
        "#A PyTorch Dataset class is defined to load images and masks, normalize inputs, and return tensors suitable for training.\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class LepraSegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.images = sorted(os.listdir(image_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.images[idx]\n",
        "\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        mask_path = os.path.join(self.mask_dir, img_name)\n",
        "\n",
        "        # ---- Load image ----\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"Image not found: {img_name}\")\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = image.astype(\"float32\") / 255.0\n",
        "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "\n",
        "        # ---- Load mask ----\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is None:\n",
        "            raise FileNotFoundError(f\"Mask not found: {img_name}\")\n",
        "\n",
        "        mask = (mask > 0).astype(\"float32\")\n",
        "        mask = torch.from_numpy(mask).unsqueeze(0)\n",
        "\n",
        "        return image, mask\n"
      ],
      "metadata": {
        "id": "Otwa5uautmMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 8. Model Architecture – U-Net\n",
        "\n",
        "#A U-Net encoder–decoder architecture with skip connections is implemented for pixel-level wound segmentation.\n",
        "import torch.nn as nn\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d1 = DoubleConv(3, 64)\n",
        "        self.d2 = DoubleConv(64, 128)\n",
        "        self.d3 = DoubleConv(128, 256)\n",
        "        self.d4 = DoubleConv(256, 512)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.mid = DoubleConv(512, 1024)\n",
        "\n",
        "        self.u4 = nn.ConvTranspose2d(1024, 512, 2, 2)\n",
        "        self.c4 = DoubleConv(1024, 512)\n",
        "\n",
        "        self.u3 = nn.ConvTranspose2d(512, 256, 2, 2)\n",
        "        self.c3 = DoubleConv(512, 256)\n",
        "\n",
        "        self.u2 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
        "        self.c2 = DoubleConv(256, 128)\n",
        "\n",
        "        self.u1 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
        "        self.c1 = DoubleConv(128, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(64, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.d1(x)\n",
        "        d2 = self.d2(self.pool(d1))\n",
        "        d3 = self.d3(self.pool(d2))\n",
        "        d4 = self.d4(self.pool(d3))\n",
        "\n",
        "        m = self.mid(self.pool(d4))\n",
        "\n",
        "        x = self.c4(torch.cat([self.u4(m), d4], dim=1))\n",
        "        x = self.c3(torch.cat([self.u3(x), d3], dim=1))\n",
        "        x = self.c2(torch.cat([self.u2(x), d2], dim=1))\n",
        "        x = self.c1(torch.cat([self.u1(x), d1], dim=1))\n",
        "\n",
        "        return self.out(x)\n"
      ],
      "metadata": {
        "id": "hAciTFEEtphE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 9. Training Configuration\n",
        "\n",
        "#The dataset, DataLoader, loss function, and optimizer are initialized for model training.\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "IMAGE_DIR = \"path of image\"\n",
        "MASK_DIR  = \"image path\"\n",
        "MODEL_DIR = \"image path\"\n",
        "\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "dataset = LepraSegmentationDataset(IMAGE_DIR, MASK_DIR)\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=2,        # safe for 512×512 on Colab GPU\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "model = UNet().to(DEVICE)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "id": "UI5OQMbztugv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 10. Model Training\n",
        "\n",
        "#The U-Net model is trained for multiple epochs using binary cross-entropy loss.\n",
        "#Model checkpoints are saved after each epoch.\n",
        "EPOCHS = 30\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, masks in tqdm(loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
        "        images = images.to(DEVICE)\n",
        "        masks = masks.to(DEVICE)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(loader)\n",
        "    print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}\")\n",
        "\n",
        "    # Save checkpoint\n",
        "    torch.save(\n",
        "        model.state_dict(),\n",
        "        f\"{MODEL_DIR}/unet_epoch_{epoch+1}.pth\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "WZDfvsrAuJOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 11. Preprocessing of Test Images\n",
        "\n",
        "#Test images are preprocessed using the same pipeline as training images to ensure consistency during inference.\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# CONFIG\n",
        "# -------------------------------r\"\n",
        "INPUT_DIR = \"image path\"\n",
        "OUTPUT_DIR = \"image path\"\n",
        "IMG_SIZE = 512\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------------------\n",
        "# VERY GENTLE STANDARDIZATION\n",
        "# -------------------------------\n",
        "def ultra_gentle_crop(image, crop_ratio=0.98):\n",
        "    h, w, _ = image.shape\n",
        "    ch, cw = int(h * crop_ratio), int(w * crop_ratio)\n",
        "    y1 = (h - ch) // 2\n",
        "    x1 = (w - cw) // 2\n",
        "    return image[y1:y1+ch, x1:x1+cw]\n",
        "\n",
        "# -------------------------------\n",
        "# PROCESS ALL IMAGES\n",
        "# -------------------------------\n",
        "for filename in os.listdir(INPUT_DIR):\n",
        "\n",
        "    if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "        continue\n",
        "\n",
        "    input_path = os.path.join(INPUT_DIR, filename)\n",
        "\n",
        "    # Load image\n",
        "    img = cv2.imread(input_path, cv2.IMREAD_COLOR)\n",
        "    if img is None:\n",
        "        print(f\"Skipping {filename} (cannot read)\")\n",
        "        continue\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Standardization\n",
        "    img_std = ultra_gentle_crop(img)\n",
        "\n",
        "    # Resize (preserve quality)\n",
        "    img_std = cv2.resize(\n",
        "        img_std,\n",
        "        (IMG_SIZE, IMG_SIZE),\n",
        "        interpolation=cv2.INTER_CUBIC\n",
        "    )\n",
        "\n",
        "    # Normalize\n",
        "    img_preprocessed = img_std.astype(np.float32) / 255.0\n",
        "\n",
        "    # Save as lossless PNG\n",
        "    save_path = os.path.join(OUTPUT_DIR, filename)\n",
        "    save_img = (img_preprocessed * 255).astype(np.uint8)\n",
        "    save_img = cv2.cvtColor(save_img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    cv2.imwrite(save_path, save_img)\n",
        "\n",
        "print(\"✅ Preprocessing completed for all images.\")\n"
      ],
      "metadata": {
        "id": "qsUH5AQ8PE_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 12. Model Loading for Inference\n",
        "\n",
        "#The trained U-Net model checkpoint is loaded and set to evaluation mode for inference on unseen test images.\n",
        "import torch\n",
        "\n",
        "# -------------------------------\n",
        "# CONFIG\n",
        "# -------------------------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "MODEL_PATH = \"path\"\n",
        "# (you can change epoch number if needed)\n",
        "\n",
        "# -------------------------------\n",
        "# LOAD MODEL\n",
        "# -------------------------------\n",
        "model = UNet().to(DEVICE)\n",
        "\n",
        "# Load trained weights\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "print(\"✅ Model loaded successfully and ready for inference\")\n"
      ],
      "metadata": {
        "id": "8C--smHAiC5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 13. Inference on Test Images\n",
        "\n",
        "#The trained model is applied to preprocessed test images to generate predicted wound segmentation masks.\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -------------------------------\n",
        "# CONFIG\n",
        "# -------------------------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "TEST_IMAGE_DIR = \"path\"\n",
        "OUTPUT_MASK_DIR = \"path\"\n",
        "MODEL_PATH = \"path\"\n",
        "\n",
        "os.makedirs(OUTPUT_MASK_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------------------\n",
        "# LOAD MODEL (already trained)\n",
        "# -------------------------------\n",
        "model = UNet().to(DEVICE)\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "print(\"✅ Model loaded for inference\")\n",
        "\n",
        "# -------------------------------\n",
        "# INFERENCE LOOP\n",
        "# -------------------------------\n",
        "with torch.no_grad():\n",
        "    for filename in tqdm(os.listdir(TEST_IMAGE_DIR), desc=\"Running inference\"):\n",
        "\n",
        "        if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(TEST_IMAGE_DIR, filename)\n",
        "\n",
        "        # Load preprocessed image\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            print(f\"Skipping {filename}\")\n",
        "            continue\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = image.astype(\"float32\") / 255.0\n",
        "\n",
        "        # Convert to tensor\n",
        "        image = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0)\n",
        "        image = image.to(DEVICE)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(image)\n",
        "\n",
        "        # Apply sigmoid + threshold\n",
        "        pred_mask = torch.sigmoid(output)\n",
        "        pred_mask = (pred_mask > 0.5).float()\n",
        "\n",
        "        # Convert to NumPy\n",
        "        pred_mask = pred_mask.squeeze().cpu().numpy()\n",
        "        pred_mask = (pred_mask * 255).astype(np.uint8)\n",
        "\n",
        "        # Save predicted mask\n",
        "        save_path = os.path.join(OUTPUT_MASK_DIR, filename)\n",
        "        cv2.imwrite(save_path, pred_mask)\n",
        "\n",
        "print(\"✅ Inference completed. Predicted masks saved.\")\n"
      ],
      "metadata": {
        "id": "79M27SsUknmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------------\n",
        "# CONFIG\n",
        "# -------------------------------\n",
        "TEST_IMAGE_DIR = \"path\"\n",
        "PRED_MASK_DIR  = \"path\"\n",
        "\n",
        "# Pick one sample image\n",
        "filename = sorted(os.listdir(TEST_IMAGE_DIR))[0]\n",
        "\n",
        "img_path = os.path.join(TEST_IMAGE_DIR, filename)\n",
        "mask_path = os.path.join(PRED_MASK_DIR, filename)\n",
        "\n",
        "# -------------------------------\n",
        "# LOAD IMAGE & MASK\n",
        "# -------------------------------\n",
        "image = cv2.imread(img_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# -------------------------------\n",
        "# CREATE OVERLAY\n",
        "# -------------------------------\n",
        "overlay = image.copy()\n",
        "overlay[mask == 255] = [255, 0, 0]  # red color for ulcer\n",
        "\n",
        "# -------------------------------\n",
        "# DISPLAY RESULTS\n",
        "# -------------------------------\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.title(\"Test Image\")\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.title(\"Predicted Mask\")\n",
        "plt.imshow(mask, cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.title(\"Overlay (Red = Ulcer)\")\n",
        "plt.imshow(overlay)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DsVjI8Oy3t0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 15. Comparison with Ground Truth Masks\n",
        "\n",
        "#Predicted masks are compared with ground truth masks to evaluate spatial alignment and segmentation accuracy.\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------------\n",
        "# CONFIG\n",
        "# -------------------------------\n",
        "TEST_IMAGE_DIR = \"path\"\n",
        "GT_MASK_DIR    = \"path\"\n",
        "PRED_MASK_DIR  = \"path\"\n",
        "\n",
        "# Pick one sample\n",
        "filename = sorted(os.listdir(TEST_IMAGE_DIR))[0]\n",
        "\n",
        "# -------------------------------\n",
        "# LOAD IMAGE & MASKS\n",
        "# -------------------------------\n",
        "img_path  = os.path.join(TEST_IMAGE_DIR, filename)\n",
        "gt_path   = os.path.join(GT_MASK_DIR, filename)\n",
        "pred_path = os.path.join(PRED_MASK_DIR, filename)\n",
        "\n",
        "image = cv2.imread(img_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "gt_mask = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
        "pred_mask = cv2.imread(pred_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# -------------------------------\n",
        "# CREATE OVERLAY (PREDICTION)\n",
        "# -------------------------------\n",
        "overlay = image.copy()\n",
        "overlay[pred_mask == 255] = [255, 0, 0]  # red = predicted ulcer\n",
        "\n",
        "# -------------------------------\n",
        "# DISPLAY COMPARISON\n",
        "# -------------------------------\n",
        "plt.figure(figsize=(20,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.title(\"Test Image\")\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,4,2)\n",
        "plt.title(\"Ground Truth Mask\")\n",
        "plt.imshow(gt_mask, cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,4,3)\n",
        "plt.title(\"Predicted Mask\")\n",
        "plt.imshow(pred_mask, cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,4,4)\n",
        "plt.title(\"Overlay (Prediction)\")\n",
        "plt.imshow(overlay)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FV8lHORH5w79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = list(range(1, 31))\n",
        "losses = [\n",
        "    0.2283, 0.1364, 0.1136, 0.1035, 0.0954,\n",
        "    0.0923, 0.0854, 0.0844, 0.0821, 0.0759,\n",
        "    0.0755, 0.0745, 0.0704, 0.0666, 0.0682,\n",
        "    0.0650, 0.0651, 0.0606, 0.0634, 0.0597,\n",
        "    0.0576, 0.0561, 0.0577, 0.0533, 0.0528,\n",
        "    0.0514, 0.0499, 0.0524, 0.0481, 0.0484\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(epochs, losses, marker='o')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.title(\"U-Net Training Loss Curve\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bWCYviQMX0Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def dice_score(pred, gt):\n",
        "    pred = pred > 0\n",
        "    gt = gt > 0\n",
        "    intersection = (pred & gt).sum()\n",
        "    return 2 * intersection / (pred.sum() + gt.sum() + 1e-8)\n"
      ],
      "metadata": {
        "id": "Vlzw9YKNY3sF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dice = dice_score(pred_mask, gt_mask)\n",
        "print(\"Dice Score:\", dice)\n"
      ],
      "metadata": {
        "id": "jp8TSMLBY4rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mclLSLmEY7ep"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}